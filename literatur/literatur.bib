@inproceedings{Baldo2015,
address = {Natal, Brasilien},
author = {Baldo, G. and Floriano, A. and Longo, B. and Bastos, T.},
booktitle = {XII Simp{\'{o}}sio Bras. Automa{\c{c}}{\~{a}}o Intel.},
file = {:Users/user/Documents/Mendeley Desktop/Baldo et al. - 2015 - Shared Control Strategy Applied To Command of an Assistive.pdf:pdf},
keywords = {This paper presents a Shared Control strategy desi,a tangential escape method of obstacle avoidance w,brain computer interface,decreasing the time spent and the mental workload,shared control,tangential escape,telepresence,to perform the same tasks. This work compares the },
mendeley-groups = {Abschlussarbeit},
mendeley-tags = {This paper presents a Shared Control strategy desi,a tangential escape method of obstacle avoidance w,decreasing the time spent and the mental workload,to perform the same tasks. This work compares the },
pages = {1--6},
title = {{Shared Control Strategy Applied To Command of an Assistive}},
year = {2015}
}



@article{Barea2002,
abstract = {This paper describes an eye-control method based on electrooculography (EOG) to develop a system for assisted mobility. One of its most important features is its modularity, making it adaptable to the particular needs of each user according to the type and degree of handicap involved. An eye model based on electroculographic signal is proposed and its validity is studied. Several human-machine interfaces (HMI) based on EOG are commented, focusing our study on guiding and controlling a wheelchair for disabled people, where the control is actually effected by eye movements within the socket. Different techniques and guidance strategies are then shown with comments on the advantages and disadvantages of each one. The system consists of a standard electric wheelchair with an on-board computer, sensors and a graphic user interface run by the computer. On the other hand, this eye-control method can be applied to handle graphical interfaces, where the eye is used as a mouse computer. Results obtained show that this control technique could be useful in multiple applications, such as mobility and communication aid for handicapped persons.},
annote = {Given the growth in life expectancy in theworld (in the countries of the Organization for Economic Cooperation and Development (OECD) it is expected that the proportion of older persons aged 60 years and older will have reached a ratio of1person in3by the year 2030), a large part of its population will experience functional problems. Aware of the dearth of applications for this sector of the population, gov- ernmentsandpublic institutionshavebeenpromoting research in this line in the recent years},
author = {Barea, R. and Boquete, L. and Mazo, M. and L{\'{o}}pez, E.},
doi = {10.1109/TNSRE.2002.806829},
file = {:Users/user/Documents/Mendeley Desktop/Barea et al. - 2002 - System for assisted mobility using eye movements based on electrooculography.pdf:pdf},
isbn = {1534-4320 (Print) 1534-4320 (Linking)},
issn = {15344320},
journal = {IEEE Trans. Neural Syst. Rehabil. Eng.},
keywords = {Control,Disabled people,Electrooculography (EOG),Eye movements,Graphical interfaces,Guidance,Wheelchair},
mendeley-groups = {Abschlussarbeit},
number = {4},
pages = {209--218},
pmid = {12611358},
title = {{System for assisted mobility using eye movements based on electrooculography}},
volume = {10},
year = {2002}
}


@Article{Bauer1979,
  author          = {Bauer, G. and Gerstenbrand, F. and Rumpl, E.},
  title           = {Varieties of the locked-in syndrome.},
  journal         = {Journal of neurology},
  year            = {1979},
  volume          = {221},
  issue           = {2},
  month           = aug,
  pages           = {77--91},
  issn            = {0340-5354},
  citation-subset = {IM},
  completed       = {1980-02-15},
  country         = {Germany},
  created         = {1980-02-15},
  issn-linking    = {0340-5354},
  keywords        = {Adult; Aged; Basilar Artery; Brain Diseases, pathology; Brain Stem; Cerebrovascular Disorders, pathology; Electroencephalography; Eye Movements; Female; Humans; Male; Middle Aged; Paralysis, diagnosis, pathology; Pons, blood supply; Syndrome},
  nlm-id          = {0423161},
  owner           = {NLM},
  pmid            = {92545},
  pubmodel        = {Print},
  pubstatus       = {ppublish},
  revised         = {2004-11-17},
  timestamp       = {2017.02.02},
}


@Book{Bommas2011,
  title     = {Anatomie und Embryologie},
  publisher = {Thieme Publishing Group},
  year      = {2011},
  editor    = {Ulrike Bommas-Ebert and Philipp Teubner and Rainer Vo{\ss}},
  doi       = {10.1055/b-002-21536},
  owner     = {user},
  timestamp = {2016.10.26},
  url       = {http://dx.doi.org/10.1055/b-002-21536},
}

@incollection{Bondke2014,
author = {{Bondke Persson}, A.; and Brenner, B.; and Burckhardt, G.; and Draguhn, A.; and Ehmke, H.; and Eysel, U.; and Fandrey, J.; and Geiger, J.; and Gekle, M.; and G{\"{o}}bel, K.; and G{\"{o}}decke, A.; and Kelm, M.; and Korbmacher, C.; and Kraft, T.; and Kr{\"{a}}mer, U.;},
booktitle = {Physiologie},
chapter = {Sehsystem },
doi = {10.1055/b-002-98019},
edition = {7. Auflage},
editor = {Pape, Hans-Christian; and Kurtz, Armin; and Silbernagl, Stefan},
file = {:Users/user/Documents/Mendeley Desktop/Bondke Persson et al. - 2014 - Okulomotorik.pdf:pdf},
isbn = {9783137960072},
mendeley-groups = {Abschlussarbeit},
pages = {776--780},
publisher = {Thieme Verlagsgruppe, Stuttgart, New York, Delhi, Rio},
title = {{Okulomotorik}},
year = {2014}
}

@article{Casper2003,
 author = {Casper, J. and Murphy, R. R.},
 title = {Human-robot Interactions During the Robot-assisted Urban Search and Rescue Response at the World Trade Center},
 journal = {Trans. Sys. Man Cyber. Part B},
 issue_date = {June 2003},
 volume = {33},
 number = {3},
 month = jun,
 year = {2003},
 issn = {1083-4419},
 pages = {367--385},
 numpages = {19},
 url = {http://dx.doi.org/10.1109/TSMCB.2003.811794},
 doi = {10.1109/TSMCB.2003.811794},
 acmid = {2226042},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
} 

@article{Desai2011,
abstract = {Telepresence robots are mobile robot platforms capable of providing two way audio and video communication. Recently there has been a surge in companies designing telepresence robots. We conducted a series of user studies at Google in Mountain View with two different commercially available telepresence robots. Based on the data collected from these user studies, we present a set of guidelines for designing telepresence robots. These essential guidelines pertain to video, audio, user interface, physical features, and autonomous behaviors.},
author = {Desai, M. and Tsui, K. M. and Yanco, H. A. and Uhlik, C.},
doi = {10.1109/TEPRA.2011.5753474},
file = {:Users/user/Documents/Mendeley Desktop/Desai et al. - 2011 - Essential features of telepresence robots.pdf:pdf},
isbn = {9781612844824},
journal = {2011 IEEE Conf. Technol. Pract. Robot Appl. TePRA 2011},
mendeley-groups = {Abschlussarbeit},
pages = {15--20},
title = {{Essential features of telepresence robots}},
year = {2011}
}

@Article{Duchowski2002,
  author    = {A. T. Duchowski},
  title     = {A breadth-first survey of eye-tracking applications},
  journal   = {Behavior Research Methods, Instruments, {\&} Computers},
  year      = {2002},
  volume    = {34},
  number    = {4},
  pages     = {455--470},
  month     = {nov},
  doi       = {10.3758/bf03195475},
  owner     = {user},
  publisher = {Springer Nature},
  timestamp = {2016.10.04},
  url       = {http://dx.doi.org/10.3758/BF03195475},
}

@article{Dunser2015,
author = {Dunser, A. and Lochner, M. and Engelke, U. and Fernandez, D. R.},
doi = {10.1109/MCG.2015.4},
file = {:Users/user/Documents/Mendeley Desktop/Dunser et al. - 2015 - Visual and Manual Control for Human-Robot Teleoperation.pdf:pdf},
isbn = {0780389123},
issn = {0272-1716},
journal = {IEEE Comput. Graph. Appl.},
mendeley-groups = {Abschlussarbeit},
number = {3},
pages = {22--32},
pmid = {25594960},
title = {{Visual and Manual Control for Human-Robot Teleoperation}},
url = {http://ieeexplore.ieee.org/search/searchresult.jsp?action=search{\&}searchField=Search{\_}All{\&}matchBoolean=true{\&}queryText=({\%}22DOI{\%}22:10.1109/MCG.2015.4)},
volume = {35},
year = {2015}
}

@INPROCEEDINGS{Drury2003, 
author={J. L. Drury and J. Scholtz and H. A. Yanco}, 
booktitle={Systems, Man and Cybernetics, 2003. IEEE International Conference on}, 
title={Awareness in human-robot interactions}, 
year={2003}, 
volume={1}, 
pages={912-918 vol.1}, 
keywords={games of skill;man-machine systems;multi-robot systems;critical incidents;human robot interaction awareness;robot activities;test arena;urban search and rescue competition;Collaboration;Collaborative software;Collaborative work;Computer science;Drives;Humans;Postal services;Robot kinematics;Robot sensing systems;Testing}, 
doi={10.1109/ICSMC.2003.1243931}, 
ISSN={1062-922X}, 
month={Oct},}

@misc{STAT2015,
  author  = {{Statistisches Bundesamt Deutschland (Destatis)}},
  title  = {Todesursachenstatistik - Deutschland (Internetausgabe). Sterbefälle 1998 bis 2015 für die spinale Muskelatrophie und verwandte Syndrome (ICD-10 Code: G12)},

  year   = {2016},
 edition    = {{Statistisches Bundesamt Deutschland (Destatis)}},
  address    = {Wiesbaden, Deutschland},
  institution    = {{Statistisches Bundesamt Deutschland (Destatis)}},
  howpublished	= "In www.destatis.de (Thematische Recherche: Zahlen \& Fakten - Gesellschaft \& Staat - Gesundheit - Todesursachen - Dokumentart: Tabelle)",
  note ={Abrufdatum: 19. Februar 2017}
}





@InProceedings{Eidam2016,
  Title     = {Towards Regaining Mobility Through Virtual Presence
               for Patients with Locked-in Syndrome},
  Author    = {S. Eidam and J. Garstka and G. Peters},
  Booktitle = {Proceedings of the 8th International Conference on
               Advanced Cognitive Technologies and Applications},
  Year      = {2016},
  Address   = {Rome, Italy},
  Pages     = {120--123},
}
@phdthesis{Eidam2015,
author = {Eidam, S.},
file = {:Users/user/Documents/Mendeley Desktop/Eidam - 2015 - Erkennung von Augengesten zur Sonifikation von Bildinhalten.pdf:pdf},
mendeley-groups = {Abschlussarbeit},
school = {FernUniversit{\"{a}}t Hagen},
title = {{Erkennung von Augengesten zur Sonifikation von Bildinhalten}},
type = {unveröffentlichte Bachelorarbeit},
year = {2015}
}

@inproceedings{Ekman2008,
 author = {Ekman, I. M. and Poikola, A. W. and M{a}k\"{a}r\"{a}inen, M. K.},
 title = {Invisible Eni: Using Gaze and Pupil Size to Control a Game},
 booktitle = {CHI '08 Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '08},
 year = {2008},
 isbn = {978-1-60558-012-8},
 location = {Florence, Italy},
 pages = {3135--3140},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/1358628.1358820},
 doi = {10.1145/1358628.1358820},
 acmid = {1358820},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {affective interfaces, computer game, eyes-only interaction, game design, pupil based interaction},
} 

@article{Ellison2004,
annote = {Owner: NLM

Added to JabRef: 2017.02.08},
author = {Ellison, L. M. and Pinto, P. A and Kim, F. and Ong, A. M. and Patriciu, A. and Stoianovici, D. and Rubin, H. and Jarrett, T. and Kavoussi, L. R.},
file = {:Users/user/Documents/Mendeley Desktop/Ellison et al. - 2004 - Telerounding and patient satisfaction after surgery.pdf:pdf},
journal = {J. Am. Coll. Surg.},
keywords = {Female,Health Care Surveys,Humans,Laparoscopy,Male,Middle Aged,Patient Satisfaction,Physician-Patient Relations,Postoperative Care,Prospective Studies,Remote Consultation,Surveys and Questionnaires,Urologic Surgical Procedures,methods},
mendeley-groups = {Abschlussarbeit},
pages = {523--530},
title = {{Telerounding and patient satisfaction after surgery.}},
volume = {199},
year = {2004}
}

@article{Fels2001,
author = {Fels, D. I. and Weiss, P. L.},
doi = {10.1016/S0169-8141(01)00020-8},
issn = {01698141},
journal = {Int. J. Ind. Ergon.},
mendeley-groups = {Abschlussarbeit},
month = {nov},
number = {5},
pages = {251--263},
title = {{Video-mediated communication in the classroom to support sick children: a case study}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169814101000208},
volume = {28},
year = {2001}
}



@misc{Gegenfurtner,
author = {Gegenfurtner, K. R. and Walter, S. and Braun, D. I.},
mendeley-groups = {Abschlussarbeit},
title = {{Visuelle Verarbeitung im Gehirn}},
url = {http://www.allpsych.uni-giessen.de/karl/teach/aka.htm},
urldate = {2017-01-30}
}

@article{Gneo2012,
author = {Gneo, M. and Schmid, M. and Conforto, S. and D'Alessio, T.},
doi = {10.1186/1743-0003-9-82},
issn = {1743-0003},
journal = {J. Neuroeng. Rehabil.},
mendeley-groups = {Aus Bib,Abschlussarbeit},
number = {1},
pages = {82},
title = {{A free geometry model-independent neural eye-gaze tracking system}},
url = {http://dx.doi.org/10.1186/1743-0003-9-82 http://jneuroengrehab.biomedcentral.com/articles/10.1186/1743-0003-9-82},
volume = {9},
year = {2012}
}

@article{Goodrich2013,
author = {Goodrich, M. A. and Crandall, J. W. and Barakova, E.},
doi = {10.1177/1557234X13502463},
file = {:Users/user/Documents/Mendeley Desktop/Goodrich, Crandall, Barakova - 2013 - Teleoperation and Beyond for Assistive Humanoid Robots.pdf:pdf},
issn = {1557234X},
journal = {Rev. Hum. Factors Ergon.},
keywords = {anthropomorphic robot,assistive robotics,humanoid robot,robotic-based therapy,teleoperation},
mendeley-groups = {Abschlussarbeit},
number = {1},
pages = {175--226},
title = {{Teleoperation and Beyond for Assistive Humanoid Robots}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885754475{\&}partnerID=40{\&}md5=05a6c69777e9c09a6ef036501e48ca92},
volume = {9},
year = {2013}
}

@incollection{Goldberg2003,
author = {Goldberg, J. H. and Wichansky, A. M.},
booktitle = {Mind's Eye},
doi = {10.1016/B978-044451020-4/50027-X},
file = {:Users/user/Documents/Mendeley Desktop/Goldberg, Wichansky - 2003 - Eye Tracking in Usability Evaluation.PDF:PDF},
mendeley-groups = {Abschlussarbeit},
pages = {493--516},
publisher = {Elsevier},
title = {{Eye Tracking in Usability Evaluation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B978044451020450027X},
year = {2003}
}

@phdthesis{Hyrskykari2006,
abstract = {The mouse and keyboard currently serve as the predominant means of passing information from user to computer. Direct manipulation of objects via the mouse was a breakthrough in the design of more natural and intuitive user interfaces for computers. However, in real life we have a rich set of communication methods at our disposal; when interacting with others, we, for example, interpret their gestures, expressions, and eye movements. This information can be used also when moving human-computer interaction toward the more natural and effective. In particular, the focus of the user's attention could often be a valuable source of information. The focus of this work is on examining the benefits and limitations in using the information acquired from a user's eye movements in the human–computer interface. For this purpose, we developed an example application, iDict. The application assists the reader of an electronic document written in a foreign language by tracking the reader's eye movements and providing assistance automatically when the reader seems to be in need of help.},
author = {Hyrskykari, A.},
file = {:Users/user/Documents/Mendeley Desktop/Hyrskykari - 2006 - Eyes in Attentive Interfaces Experiences from Creating iDict, A Gaze-Aware Reading Aid.pdf:pdf},
isbn = {951-44-6643-8},
mendeley-groups = {Abschlussarbeit,Abschlussarbeit/2{\_}Eyetracking},
pages = {193},
school = {University of Tampere, Finnland},
title = {{Eyes in Attentive Interfaces: Experiences from Creating iDict, A Gaze-Aware Reading Aid}},
url = {http://acta.uta.fi},
year = {2006}
}

@CONFERENCE{Haming2010,
  author = {H{\"a}ming, K. and Peters, G.},
  title = {An Alternative Approach to the Revision of Ordinal Conditional 
        Functions in the Context of Multi-Valued Logic},
  booktitle = {20th International Conference on Artificial Neural Networks},
  year = {2010},
  editor = {Konstantinos Diamantaras and Wlodek Duch and Lazaros S. Iliadis},
  pages = {200--203},
  address = {Thessaloniki, Greece},
  month = {September 15--18},
  publisher = {Springer-Verlag},
}



@inproceedings{Herring2016,
 author = {Herring, S. C. and Fussell, S. R. and Kristoffersson, A. and Mutlu, B. and Neustaedter, C. and Tsui, K. M.},
 title = {The Future of Robotic Telepresence: Visions, Opportunities and Challenges},
 booktitle = {Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '16},
 year = {2016},
 isbn = {978-1-4503-4082-3},
 location = {Santa Clara, California, USA},
 pages = {1038--1042},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2851581.2886423},
 doi = {10.1145/2851581.2886423},
 acmid = {2886423},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CSCW, remote collaboration, robots, telepresence},
}

@techreport{Hollomon2017,
address = {Oklahoma City},
author = {Hollomon, M. J. and Kratchounova, D. and Newton, D. C. and Gildea, K. and Knecht, W. R.},
file = {:Users/user/Documents/Mendeley Desktop/Hollomon et al. - 2017 - Current Status of Gaze Control Research and Technology Literature Review.pdf:pdf},
institution = {Civil Aerospace Medical Institute Federal Aviation Administration },
mendeley-groups = {Abschlussarbeit},
title = {{Current Status of Gaze Control Research and Technology Literature Review}},
url = {http://www.faa.gov/go/oamtechreports},
year = {2017}
}

@InProceedings{Istance:2006,
  author        = {Istance, H.},
  title         = {Communication Through Eye-gaze: Where We Have Been, Where We Are Now and Where We Can Go from Here},
  booktitle     = {Proceedings of the 2006 Symposium on Eye Tracking Research \&Amp; Applications},
  year          = {2006},
  series        = {ETRA '06},
  publisher     = {ACM},
  location      = {San Diego, California},
  isbn          = {1-59593-305-0},
  pages         = {9--9},
  doi           = {10.1145/1117309.1117311},
  url           = {http://doi.acm.org/10.1145/1117309.1117311},
  acmid         = {1117311},
  address       = {New York, NY, USA},
  numpages      = {1},
}

@manual{IRobot2010,
author = {{iRobot Corporation}},
file = {:Users/user/Documents/Mendeley Desktop/iRobot Corporation - 2010 - iRobot Create Open Interface (OI) Specification.pdf:pdf},
institution = {iRobot Corporation},
mendeley-groups = {Abschlussarbeit},
pages = {25},
title = {{iRobot Create Open Interface (OI) Specification}},
url = {https://www.irobot.com/filelibrary/pdfs/hrd/create/Create Open Interface{\_}v2.pdf},
year = {2010}
}

@inproceedings{ito2011hand,
  title={Hand gesture-based manipulation of a personalized avatar robot in remote communication},
  author={Ito, T.},
  booktitle={Symposium on Human Interface},
  pages={425--434},
  year={2011},
  organization={Springer}
}

@article{Jacob2003,
author = {Jacob, R. J. K. and Karn, K. S.},
file = {:Users/user/Documents/Mendeley Desktop/Jacob, Karn - 2003 - Eye Tracking in Human-Computer Interaction and Usability Research. Ready to Deliver the Promises.pdf:pdf},
journal = {Mind},
mendeley-groups = {Abschlussarbeit},
pages = {4},
title = {{Eye Tracking in Human–Computer Interaction and Usability Research: Ready to Deliver the Promises}},
volume = {2},
year = {2003}
}

@Book{Joos2003,
  title         = {Psycholinguistik / Psycholinguistics},
  publisher     = {Gruyter, Walter de GmbH},
  year          = {2003},
  author        = {Joos, M. Rötting, M. Velichkovsky, B.},
  date          = {2003-01-01},
  ean           = {9783110194043},
  owner         = {user},
  timestamp     = {2016.10.26},
  url           = {http://www.ebook.de/de/product/16110641/psycholinguistik_psycholinguistics.html},
}

@book{Keyes2010,
	author 		= {Keyes, B. and Micire, M. and Drury, J. L. and Yanco, H. A.},
booktitle = {Human-Robot Interact},
editor = {{Daisuke Chugo}},
file = {:Users/user/Documents/Mendeley Desktop/Keyes et al. - 2010 - Improving Human-Robot Interaction through Interface Evolution.pdf:pdf},
isbn = {978-953-307-051-3},
mendeley-groups = {Abschlussarbeit},
pages = {183--202},
title = {{Improving Human-Robot Interaction through Interface Evolution}},
year = {2010}
}

@article{Khanna201196,
abstract = {Locked-in syndrome is one of the most disabling states characterized by the preservation of conscious mind within a quadriplegic and anarthric body. Recently, there has been increased public awareness about this rare condition, and more cases are reported. The commonest causative lesion is bilateral ventral pontine damage secondary to vertebrobasilar artery occlusion. Clinicians need to be familiar with the condition because there is a high chance of erroneous diagnosis, such as coma or vegetative state, after a prolonged unconscious state. It is often the relatives or carers who recognize the conscious state first and report that the patient can communicate through his eyes. Because of complications, such as aspiration and sepsis, about 40–70{\%} of sufferers die in acute phase of illness. However, advancements in medical care, rehabilitation, and communication technology have enabled many chronic locked-in syndrome patients to lead meaningful lives in the society with the help of family and friends.},
author = {Khanna, K. and Verma, A. and Richard, B.},
doi = {http://dx.doi.org/10.1016/j.jcgg.2011.08.001},
file = {:Users/user/Documents/Mendeley Desktop/Khanna, Verma, Richard - 2011 - “The locked-in syndrome” Can it be unlocked.pdf:pdf},
issn = {2210-8335},
journal = {J. Clin. Gerontol. Geriatr.},
keywords = {Brain stem,Communication aides,Locked-in syndrome,Rehabilitation,Stroke},
mendeley-groups = {Abschlussarbeit},
number = {4},
pages = {96--99},
title = {{“The locked-in syndrome”: Can it be unlocked?}},
url = {//www.sciencedirect.com/science/article/pii/S2210833511000566},
volume = {2},
year = {2011}
}


@incollection{Krahn2011,
address = {Stuttgart},
author = {Krahn, V. and Rien{\"{a}}cker, J. and Rude, J.},
booktitle = {Kurzlehrb. Anat. und Embryologie},
chapter = {15.1},
doi = {10.1055/b-002-21536},
editor = {Bommas-Ebert, Ulrike and Teubner, Philipp and Vo{\ss}, Rainer},
file = {:Users/user/Documents/Mendeley Desktop/Krahn, Rien{\"{a}}cker, Rude - 2011 - Das Auge.pdf:pdf},
isbn = {9783131355331},
mendeley-groups = {Abschlussarbeit},
pages = {436 -- 443},
publisher = {Georg Thieme Verlag},
title = {{Das Auge}},
url = {http://www.thieme-connect.de/products/ebooks/book/10.1055/b-002-21536},
year = {2011}
}

@Article{Kristoffersson2013,
  author    = {A. Kristoffersson and S. Coradeschi and A. Loutfi},
  title     = {A Review of Mobile Robotic Telepresence},
  journal   = {Advances in Human-Computer Interaction},
  year      = {2013},
  volume    = {2013},
  pages     = {1--17},
  doi       = {10.1155/2013/902316},
  owner     = {user},
  publisher = {Hindawi Publishing Corporation},
  timestamp = {2016.10.02},
  url       = {http://dx.doi.org/10.1155/2013/902316},
}
@book{Kurt2007,
author = {Kurt, T. E.},
title = {{Hacking Roomba}},
publisher = {Wiley Publishing, Inc.},
file = {:Users/user/Documents/Mendeley Desktop/Kurt - 2007 - Roomba.pdf:pdf},
isbn = {9780470072714},
mendeley-groups = {Abschlussarbeit},
year = {2007}
}
@article{Labonte2010,
abstract = {Being able to act remotely in our homes could be very useful in providing various services such as surveillance and remote interventions, which are key features for telehomecare applications. In addition to navigation and environmental challenges that a telepresence robot would face in home settings, the system requires an appropriate teleoperation interface for safe and efficient usage by novice users. This paper describes the design criteria and characterizes visualization and control modalities of user interfaces with a real robot. By considering the user's needs along with the current state of the art in teleoperation interfaces, two novel mixed-reality visualization modalities are compared with standard video-centric and map-centric perspectives. We report teleoperation trials under six different task scenarios with a sample of 37 novice operators in homelike conditions. The results based on three quantitative metrics and one qualitative metric outline under which conditions the novel mixed-reality visualization modalities significantly improve the performance of novice users.},
author = {Labonte, D. and Boissy, Pa. and Michaud, F.},
doi = {10.1109/TSMCB.2009.2038357},
file = {:Users/user/Documents/Mendeley Desktop/Labonte, Boissy, Michaud - 2010 - Comparative analysis of 3-D robot teleoperation interfaces with novice users.pdf:pdf},
isbn = {1083-4419 VO  - 40},
issn = {10834419},
journal = {IEEE Trans. Syst. Man, Cybern. Part B Cybern.},
keywords = {Mixed perspective,teleassistive robotic,user interface,virtual reality (VR)},
mendeley-groups = {Abschlussarbeit},
number = {5},
pages = {1331--1342},
pmid = {20106745},
title = {{Comparative analysis of 3-D robot teleoperation interfaces with novice users}},
volume = {40},
year = {2010}
}

@article{Lupu2013,
abstract = {In the last decade, the development of eye tracking (ET) systems represented a challenge for researchers and different companies in the area of IT, medical equipment or multimedia commercial devices. An eye tracking system is based on a device to track the movement of the eyes to know exactly where the person is looking and for how long. It also involves software algorithms for pupil detection, image processing, data filtering and recording eye movement by means of fixation point, fixation duration and saccade as well. A large variety of hardware and software approaches were implemented by research groups or companies according to technological progress. The suitable devices for eye movement acquiring and software algorithms are chosen in concordance with the application requirements. Some vendors (e.g. SensoMotoric Instruments, Tobii or MyGaze) have invested in eye tracking technology, but their solutions are focused on commercial remote camera-based eye-tracker systems for which the light source and camera are permanently affixed to a monitor. Because these commercial systems including software and support are expensive some mobile and low cost devices for eye tracking were developed by some research groups. The eye tracking applications covers human computer interaction, brain computer interaction, assistive technology, e-learning, psychology investigation, pilot training assistance, virtual and augmented reality and so on.},
author = {Lupu, R. G. and Ungureanu, F.},
file = {:Users/user/Documents/Mendeley Desktop/Lupu, Ungureanu - 2013 - A survey of eye tracking methods and applications.pdf:pdf},
journal = {Math. Subj. Classif.},
keywords = {68N19,68U35,94A12,eye tracking algorithms,eye tracking applications,human computer interaction},
mendeley-groups = {Abschlussarbeit},
number = {3},
pages = {72--86},
title = {{A survey of eye tracking methods and applications}},
volume = {LXIII},
year = {2013}
}

@book{majaranta2011,
  title={Gaze Interaction and Applications of Eye Tracking: Advances in Assistive Technologies: Advances in Assistive Technologies},
  author={Majaranta, P.},
  isbn={9781613500996},
  lccn={2011026203},
  series={Premier reference source},
  url={https://books.google.de/books?id=HuWeBQAAQBAJ},
  year={2011},
  publisher={Medical Information Science Reference}
}

@InCollection{Majaranta2014,
  author        = {P. Majaranta and A. Bulling},
  title         = {Eye Tracking and Eye-Based Human{\textendash}Computer Interaction},
  booktitle     = {Advances in Physiological Computing},
  publisher     = {Springer Science $\mathplus$ Business Media},
  year          = {2014},
  series        = {Human{\textendash}Computer Interaction Series},
  chapter       = {3},
  pages         = {39--65},
  owner         = {user},
  timestamp     = {2016.10.07},
  url           = {http://dx.doi.org/10.1007/978-1-4471-6392-3_3},
}

@article{Michaud2010,
abstract = {Telehealth assistive technologies for homes constitute a very promising avenue to decrease load on the health care system, to reduce hospitalization period and to improve quality of life. Teleoperated from a distant location, a mobile robot can become a beneficial tool in health applications. However, design issues related to such systems are broad and mostly unexplored (e.g., locomotion and navigation in-home settings, remote interaction and patient acceptability, evaluation of clinical needs and their integration into health care information systems). Designing a safe and effective robotic system for in-home teleassistance requires taking into consideration the complexities of having novice users remotely navigate a mobile robot in a home environment while they interact with patients. This paper presents the progress made by adopting an interdisciplinary and exploratory design methodology to develop a telepresence assistive mobile robot for homecare assistance of elderly people. Preliminary studies using robots, focus groups and interviews allowed us to derive preliminary specifications to design a new mobile robotic system named Telerobot. Telerobot's locomotion mechanism provides improved mobility when moving on uneven surfaces, helping to provide stable video feed to the user. Its control system is implemented for safe teleoperation. A study involving 10 rehabilitation professionals confirms that the system is usable in-home environments. Analysis of teleoperation strategies used by novice teleoperators suggest that it is essential in a home environment that the teleoperation interface provides the user with a visual feedback of the objects surrounding the robot, their distances relative to the robot and the size of the robot in the environment. Enhanced user interfaces to augment the operator's perception of the environment were elaborated and tested in controlled conditions. Based on the progress made so far, the paper outlines issues that will be addressed in future work with the objective of coming up with a complete, efficient and usable in-home teleassistance mobile robotic system. {\textcopyright} 2010 Elsevier Ltd. All rights reserved.},
author = {Michaud, F. and Boissy, P. and Labont{\'{e}}, D. and Brire, S. and Perreault, K. and Corriveau, H. and Grant, A. and Lauria, M. and Cloutier, R. and Roux, M. A. and Iannuzzi, D. and Royer, M. P. and Ferland, F. and Pomerleau, F. and L{\'{e}}tourneau, D.},
doi = {10.1016/j.mechatronics.2010.01.010},
file = {:Users/user/Documents/Mendeley Desktop/Michaud et al. - 2010 - Exploratory design and evaluation of a homecare teleassistive mobile robotic system.pdf:pdf},
isbn = {0957-4158},
issn = {09574158},
journal = {Mechatronics},
keywords = {In-home teleassistance,Locomotion,Mobile telepresence,Teleoperation,Usability,User interface},
mendeley-groups = {Abschlussarbeit,Abschlussarbeit/3{\_}TPS},
number = {7},
pages = {751--766},
publisher = {Elsevier Ltd},
title = {{Exploratory design and evaluation of a homecare teleassistive mobile robotic system}},
url = {http://dx.doi.org/10.1016/j.mechatronics.2010.01.010},
volume = {20},
year = {2010}
}


@article{Minsky1980,
author = {{Minsky, M.}},
journal = {OMNI Magazine},
mendeley-groups = {Abschlussarbeit},
title = {{Telepresence}},
url = {http://web.media.mit.edu/{~}minsky/papers/Telepresence.html},
year = {1980}
}
@article{Moyle2014,
 author    = {W. Moyle and C. Jones and M. Cooke and S. O'Dwyer and B. Sung and S. Drummond},
  title     = {Connecting the person with dementia and family: a feasibility study of a telepresence robot},
  journal   = {{BMC} Geriatr},
  year      = {2014},
  volume    = {14},
  number    = {1},
  month     = {jan},
  doi       = {10.1186/1471-2318-14-7},
  owner     = {user},
  publisher = {Springer Nature},
  timestamp = {2016.10.02},
  url       = {http://dx.doi.org/10.1186/1471-2318-14-7},
}}

@article{Jouppi,
abstract = {Mutually-Immersive Mobile Telepresence uses a teleoper-ated robotic surrogate to visit remote locations as a substitute for physical travel. Our goal is to recreate to the greatest ex-tent possible, both for the user and the people at the remote location, the sensory experience relevant for business inter-actions of the user actually being in the remote location. The system includes multi-channel bidirectional video and audio on a mobile platform as well as haptic feedback. This paper describes our first system prototypes and initial experiences using them.},
author = {Jouppi, N. P.},
file = {:Users/user/Documents/Mendeley Desktop/Jouppi - Unknown - First Steps Towards Mutually-Immersive Mobile Telepresence.pdf:pdf},
keywords = {Audio Conferencing,Haptics,Human Visual Perception,Multi-Channel Audio,Multi-User Networked Applications,Multimedia,Robotics,User Interface Hardware,Video Conferencing},
title = {{First Steps Towards Mutually-Immersive Mobile Telepresence}},
 booktitle = {Proceedings of the 2002 ACM Conference on Computer Supported Cooperative Work},
 series = {CSCW '02},
 year = {2002},
 isbn = {1-58113-560-2},
 location = {New Orleans, Louisiana, USA},
 pages = {354--363},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/587078.587128},
 doi = {10.1145/587078.587128},
 acmid = {587128},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@incollection{packer2002,
author={Heilig, M.},
 title = {The cinema of the future (Original work published in 1955)},
 editor = {Packer, R. and Jordan, K.},
 booktitle = {Multimedia : from Wagner to virtual reality},
 publisher = {W. W. Norton \& Company},
 year = {2002},
 address = {New York},
 isbn = {978-0393323757},
 pages={239–251}
 }
 
@booklet{Peters2013,
annote = {Augen f{\"{u}}hren eine hohe Anzahl von Bewegungen durch.
Bei der erfassen der Umwelt wird die Bewegung des Augapfels, der Pupille, des Liedes und des Kopfes benutzt.},
author = {Peters, G. and Kerdels, J.},
file = {:Users/user/Documents/Mendeley Desktop/Peters - 2013 - Einf{\"{u}}hrung in Mensch-Computer-Interaktion.pdf:pdf},
mendeley-groups = {Abschlussarbeit},
title = {{Einf{\"{u}}hrung in Mensch-Computer-Interaktion}},
howpublished	= {Vorlesungsskript Wintersemester 2012/2013 --{FernUniversit{\"{a}}t Hagen}},
school = {FernUniversit{\"{a}}t Hagen},
year = {2013}

}

@article{Poole2005,
abstract = {Eye-movement tracking is a method that is increasingly being employed to study usability issues in HCI contexts. The objectives of the present chapter are threefold. First, we introduce the reader to the basics of eye-movement technology, and also present key aspects of practical guidance to those who might be interested in using eye tracking in HCI research, whether in usability-evaluation studies, or for capturing people's eye movements as an input mechanism to drive system interaction. Second, we examine various ways in which eye movements can be systematically measured to examine interface usability. We illustrate the advantages of a range of different eyemovement metrics with reference to state-of-the-art usability research. Third, we discuss the various opportunities for eye-movement studies in future HCI research, and detail some of the challenges that need to be overcome to enable effective application of the technique in studying the complexities of advanced interactive-system use.},
annote = {Eyetracking als Eingabeger{\"{a}}t.
Augenbewegungen die mittels eines Eye-Trackers erfasst werden, lassen sich als Steuersignale f{\"{u}}r die Benutzung einer Benutzerschnittstelle verwenden. So kann der Benutzer durch Blickbewegungen einen Courser auf dem Bildschirm bewegen und Icons der Benutzeroberfl{\"{a}}che beispielsweise durch l{\"{a}}ngere Fixation oder Blinzeln selektieren. Diese Art der Interaktion kann so ausgelegt werden, dass keine zust{\"{a}}tzliche manuelle oder andersartige Interaktion notwendig ist und so rein auf Grundlage der motorischen F{\"{a}}higkeiten der Augen- und Lidmuskulatur basiert. Problematisch im Zusammenhang mit dieser Art der Steuerung ist das sogenannte $\backslash$enquote{\{}Midas Touch{\}} Problem. Hierunter versteht man, dass w{\"{a}}hrend der Augenbewegung nicht jede Bewegung eine motorische Intention haben muss, sondern im Rahmen der sensorischen Wahrnehmung durch das System missinterpretiert wird und mit ungewollte Selektion von Komponenten der Benutzerschnittstelle einhergehen kann. Die Midas Touch Problematik kann durch Kombination mit anderen Eingabeger{\"{a}}ten wie beispielsweise der Spracheingabe verbessert werden. Ferner k{\"{o}}nnen mehrere Augenbewegungen kombiniert werden. $\backslash$cite{\{}Poole2005{\}}},
author = {Poole, A. and Ball, L. J.},
doi = {10.4018/978-1-59140-562-7},
file = {:Users/user/Documents/Mendeley Desktop/Poole, Ball - 2005 - Eye Tracking in Human-Computer Interaction and Usability Research Current Status and Future Prospects.pdf:pdf},
isbn = {978-1-5914-0562-7},
issn = {09535438},
journal = {Encycl. Human-Computer Interact.},
mendeley-groups = {Abschlussarbeit},
pages = {211--219},
pmid = {20389675},
title = {{Eye Tracking in Human-Computer Interaction and Usability Research: Current Status and Future Prospects}},
year = {2005}
}

@article{Rossler2009,
author = {R{\"{o}}{\ss}ler, P.},
doi = {10.5445/KSP/1000010487},
file = {:Users/user/Documents/Mendeley Desktop/R{\"{o}}{\ss}ler - 2009 - Telepr{\"{a}}sente Bewegung und haptische Interaktion in ausgedehnten entfernten Umgebungen.pdf:pdf},
isbn = {978-3-86644-346-4},
issn = {1867-3813},
title = {{Telepr{\"{a}}sente Bewegung und haptische Interaktion in ausgedehnten entfernten Umgebungen}},
url = {https://publikationen.bibliothek.kit.edu/1000010487},
year = {2009}
}

@INPROCEEDINGS{Scholtz04,
    author = {J. Scholtz and J. Young},
    title = {Evaluation of human-robot interaction awareness in search and rescue},
    booktitle = {In Proceedings of the 2004 International Conference on Robotics and Automation},
    year = {2004}
}

@manual{SMI2011,
address = {Teltow/Berlin},
author = {{SensoMotoric Instruments GmbH}},
file = {:Users/user/Documents/Mendeley Desktop/SensoMotoric Instruments GmbH - 2011 - iView X System Manual.pdf:pdf},
institution = {SensoMotoric Instruments GmbH},
keywords = {iView X System Manual SMI},
mendeley-groups = {Abschlussarbeit},
number = {Version 2.7},
pages = {545},
title = {{iView X System Manual}},
year = {2011}
}


@book{sheridan1992,
  title={Telerobotics, automation, and human supervisory control},
  author={Sheridan, T. B.},
  year={1992},
  publisher={MIT press}
}
@Book{Thoemke2008,
  author        = {Th{\"o}mke, F.},
  title         = {Augenbewegungsst{\"o}rungen: ein klinischer Leitfaden f{\"u}r Neurologen},
  year          = {2008},
  pages			= {368},
  publisher     = {Georg Thieme Verlag},
  owner         = {user},
  isbn = {9783131287427},
}


@article{steven2005,
author = {{Steven Laureys}, {\~{A}.} and Pellas, F. and {Van Eeckhout}, P. and Ghorbel, S. and Schnakers, C. and Perrin, F. and Berre, J. and Faymonville, M.--E. and Pantke, K.--H. and Damas, F. and Others},
file = {:Users/user/Documents/Mendeley Desktop/Steven Laureys et al. - 2005 - The locked-in syndrome what is it like to be conscious but paralyzed and voiceless.pdf:pdf},
journal = {Prog. Brain Res.},
mendeley-groups = {Abschlussarbeit,Abschlussarbeit/1{\_}MCI},
pages = {495--511},
title = {{The locked-in syndrome: what is it like to be conscious but paralyzed and voiceless?}},
volume = {150},
year = {2005}
}


@InProceedings{Tonin2011,
  author    = {L. Tonin and T. Carlson and R. Leeb and J. {del R. Millan}},
  title     = {Brain-controlled telepresence robot by motor-disabled people},
  booktitle = {2011 Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society},
  year      = {2011},
  month     = {aug},
  publisher = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  doi       = {10.1109/iembs.2011.6091049},
  file      = {:Users/user/Dropbox/Abschlussarbeit MCI/Literaturpapers/ Brain-controlled telepresence robot by motor-disabled people.pdf:PDF},
  owner     = {user},
  timestamp = {2016.10.07},
  url       = {http://dx.doi.org/10.1109/IEMBS.2011.6091049},
}

@inproceedings{tsui2011,
  title={Designing Telepresence Robot Systems for Use by People with Special Needs},
  author={Tsui, K. M. and Norton, A. and Brooks, D. and Yanco, H. A. and Kontak, D.},
  booktitle={International Symposium on Quality of Life Technologies 2011: Intelligent Systems for Better Living, held in conjunction with RESNA 2011 as part of FICCDAT},
  year={2011}
}

@inproceedings{Tsui2011b,
 author = {Tsui, K. M. and Desai, M. and Yanco, H. A. and Uhlik, C.},
 title = {Exploring Use Cases for Telepresence Robots},
 booktitle = {Proceedings of the 6th International Conference on Human-robot Interaction},
 series = {HRI '11},
 year = {2011},
 isbn = {978-1-4503-0561-7},
 location = {Lausanne, Switzerland},
 pages = {11--18},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1957656.1957664},
 doi = {10.1145/1957656.1957664},
 acmid = {1957664},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {remote presence, teleoperation, video conferencing},
} 

@Article{Tsui2014,
  author    = {K. M. Tsui and E. McCann and A. McHugh and M. Medvedev and H. A. Yanco and D. Kontak and J. L. Drury},
  title     = {Towards designing telepresence robot navigation for people with disabilities},
  journal   = {International Journal of Intelligent Computing and Cybernetics},
  year      = {2014},
  volume    = {7},
  number    = {3},
  pages     = {307--344},
  month     = {aug},
  doi       = {10.1108/ijicc-10-2013-0044},
  editor    = {Dr Guilherme N. DeSouza},
  owner     = {user},
  publisher = {Emerald},
  timestamp = {2016.10.02},
  url       = {http://dx.doi.org/10.1108/IJICC-10-2013-0044},
}

@article{VanMiddendorp2014a,
author = {van Middendorp, J. J. and Watkins, F. and Park, C. and Landymore, H.},
doi = {10.1038/sc.2014.219},
file = {:Users/user/Documents/Mendeley Desktop/van Middendorp et al. - 2014 - Eye-tracking computer systems for inpatients with tetraplegia findings from a feasibility study.pdf:pdf},
isbn = {1476-5624$\backslash$r1362-4393},
issn = {1476-5624},
journal = {Spinal Cord},
keywords = {ARM,DISABILITY,SPINAL-CORD-INJURY,UPPER EXTREMITY},
mendeley-groups = {Abschlussarbeit},
number = {3},
pages = {221--225},
pmid = {25448188},
publisher = {Nature Publishing Group},
title = {{Eye-tracking computer systems for inpatients with tetraplegia: findings from a feasibility study.}},
url = {https://apps.webofknowledge.com/full{\_}record.do?product=UA{\&}search{\_}mode=GeneralSearch{\&}qid=2{\&}SID=1C9J9JhAeaJLMY8lPrk{\&}page=1{\&}doc=5},
volume = {53},
year = {2014}
}


@article{Yanco2004,
author = {Yanco, H. A. and Drury, J. L. and Scholtz, J.},
file = {:Users/user/Documents/Mendeley Desktop/Yanco, Drury, Scholtz - 2004 - Beyond Usability Evaluation Analysis of Human-Robot Interaction at a Major Robotics Competition.pdf:pdf},
journal = {J. Human-Computer Interact.},
mendeley-groups = {Abschlussarbeit},
pages = {117--149},
title = {{Beyond Usability Evaluation: Analysis of Human-Robot Interaction at a Major Robotics Competition}},
year = {2004}
}

@INPROCEEDINGS{Yanco2004-2, 
author={H. A. Yanco and J. Drury}, 
booktitle={2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)}, 
title={“Where am I?“ Acquiring situation awareness using a remote robot platform}, 
year={2004}, 
volume={3}, 
pages={2835--2840},  
doi={10.1109/ICSMC.2004.1400762}, 
ISSN={1062-922X}, 
month={Oct},}

@article{Yanco2007,
author = {Yanco, H. A and Keyes, B. and Drury, J. L. and Nielsen, C. W. and Few, D. A. and Bruemmer, D. J.},
file = {:Users/user/Documents/Mendeley Desktop/Yanco et al. - 2007 - Evolving Interface Design for Robot Search Tasks.pdf:pdf},
journal = {J. F. Robot.},
pages = {79--799},
title = {{Evolving Interface Design for Robot Search Tasks}},
volume = {24},
year = {2007}
}

@article{Young1975,
author = {Young, L. R. and Sheena, D.},
doi = {10.3758/BF03201553},
file = {:Users/user/Documents/Mendeley Desktop/Young, Sheena - 1975 - Survey of eye movement recording methods.pdf:pdf},
isbn = {1554-351X},
issn = {1554-351X},
journal = {Behav. Res. Methods Instrum.},
mendeley-groups = {Abschlussarbeit/2{\_}Eyetracking},
number = {5},
pages = {397--429},
title = {{Survey of eye movement recording methods}},
volume = {7},
year = {1975}
}