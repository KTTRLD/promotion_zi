\externaldocument{03_fragestellung}

\chapter{Einführung}
\label{chapter:einfuehrung}

Das Austauschen und das Teilen von Gefühlen, innersten Absichten und Gedanken mit anderen Personen erscheint für viele Menschen selbstverständlich. Auch die freie Wahl des eigenen Aufenthaltsortes und die Interaktion in und mit dieser Umgebung ist ein Grundbedürfnis eines jeden Menschen und für die meisten Personen normal. Doch für Personen mit Sprach- oder Bewegungseinschränkungen stellt sowohl die Kommunikation,- als auch die aktive Interaktion mit der unmittelbaren Umgebung eine Herausforderung dar. Dies bedeutet nicht selten einen Einschnitt in die Lebensführung und die allgemeine Lebensqualität der betroffenen Personen. Unterstützende technische Systeme können hierbei einen Beitrag zur Verbesserung der Situation von Personen mit Sprach- oder Bewegungseinschränkungen leisten. Zur Gruppe der unterstützenden technischen Systeme zählen im Bereich der Medizin und Gesundheitsversorgung immer häufiger auch Eyetracking-Systeme sowie mobile Robotersysteme. Die Kombination dieser beiden Systeme bietet das Potenzial, die Kommunikations- und Interaktionsfähigkeiten mit der näheren oder entfernteren Umgebung speziell für Personen mit Sprach- oder Bewegungseinschränkungen zu erweitern, um dieser Personengruppe zu einer aktiven und selbstbestimmten Lebensführung zu verhelfen. 

\section{Motivation}
\label{section:motivation}

Eine Personengruppe, die im Sommer 2014 besondere mediale Aufmerksamkeit durch die sogenannte \enquote{Ice Bucket Challenge} (deutsch Eiskübelherausforderung\footnote{\url{https://de.wikipedia.org/wiki/ALS_Ice_Bucket_Challenge} (letzter Aufruf: 08. März 2017)}) erhalten hatte, sind Personen mit \aclp{als} (ALS). Ziel dieser Spendenkampagne war es, die Forschung \bzgl der Ätiologie der Erkrankung und eventuelle Therapiemöglichkeiten voranzutreiben. \acs{als} ist eine schwere neuromuskuläre Erkrankung, die das Zentralnervensystem schädigt und in aller Regel zu einem vorzeitigen Tod führt. Im Jahr 2015 starben allein in Deutschland 2044 Personen (je 100.000 Einwohner) an dieser Erkrankung, wobei die Zahl seit 1998 ansteigend ist (\vgl \cite{STAT2015}).

\begin{comment}
\begin{figure}[ht]
   \begin{minipage}[t]{\linewidth} 
      \centering 
     %\includegraphics[scale=1]{bilder/grundlagen/als.pdf}
     % \includegraphics[width=1\textwidth]{bilder/grundlagen/1als.pdf}
      \includegraphics[scale=4.8]{bilder/grundlagen/1als.pdf}
   \end{minipage}% 
   \caption{Sterbefälle 1998 bis 2015 für die spinale Muskelatrophie und verwandte Syndrome (ICD-10 Code: G12), Statistisches Bundesamt (Destatis), 2017. In www.destatis.de (Thematische Recherche: Zahlen \& Fakten - Gesellschaft \& Staat - Gesundheit - Todesursachen - Dokumentart: Tabelle). Abrufdatum: 19. Februar 2017 \protect\footnotemark }\label{fig:stat} 
\end{figure} 
\end{comment}
Die Erkrankung führt früher oder später in ein Stadium des \aclp{lis}~(LIS). Dies ist ein Zustand, der mit erhaltener kognitiver Fähigkeit einhergeht, bei gleichzeitiger totaler oder subtotaler Bewegungseinschränkung. \acs{als} ist jedoch nur eine von vielen Ursachen, die zu diesem Zustand führen können. Auch traumatisch bedingte Verletzungen des Rückenmarks, Durchblutungsstörungen des Gehirns oder entzündliche Prozesse im Gehirn oder Rückenmark können unter Umständen das \acs{lis} auslösen.
Personen mit \acs{lis} bleiben oftmals nur die Augen als einziger Kommunikationskanal zur Außenwelt erhalten. 

Eine Kommunikation mit der Umgebung nur auf der Grundlage von Augenbewegungen zu ermöglichen, stellt jedoch eine große Herausforderung dar. Hier haben sich dank technischer Unterstützung, die zu Beginn verwendeten statischen Kommunikationshilfen (wie beispielsweise Alphabet- und Buchstabentafeln\footnote{\url{http://www.hmnw.de/pdf/buchstabentafel-alphabetisch.pdf} (letzter Aufruf: 01. März 2017)}),- zunehmend hin zu technischen Kommunikationssystemen, basierend auf Eyetracking-Systemen, entwickelt\footnote{\url{https://www.augen-steuerung.de/anwendungen/} (letzter Aufruf: 01. März 2017)}. Eyetracking-Systeme können Augengesten ohne invasive Methoden sichtbar und interpretierbar machen. Durch diesen Fortschritt ist die häufig aufwendige Interaktion mit einer interagierenden Person nicht mehr notwendig. Die Interaktion mit dem Computersystem basiert jedoch weiterhin häufig auf statischen Inhalten,- wie beispielsweise auf einer am Computerbildschirm dargestellten Tastatur. Hierdurch ist es möglich, Sätze zu schreiben, die anschließend durch eine Sprachausgabe ausgegeben werden.

Eine alternative Lösung zu diesem \enquote{tastaturbasierten} Konzept zeigt die Arbeit von Eidam~(2015)~\cite{Eidam2015}. Hier werden mittels eines entwickelten Softwareprototyps Alltagsgegenstände in einer statischen Bildschirmszene erkannt und passende Handlungsoptionen in Abhängigkeit des identifizierten Objekts durch Augengesten selektiert. Hierdurch kann eine Interaktion mit dargestellten Alltagsgegenständen erzielt und somit eine Alternative zur Eingabe von Wörtern und Sätzen bereitgestellt werden. 

Aufbauend auf diesen Überlegungen kann in einem weiteren Schritt darüber nachgedacht werden, das System von Eidam (2015) durch einen dynamischen und flexiblen Blickbereich zu erweitern, um unterschiedliche Gegenstände gezielt in der näheren Umgebung zu selektieren. Um diese Flexibilität zu erreichen, bieten sich mobile Robotersysteme,- wie beispielsweise das vom Unternehmen Double Robotics entwickelte System \textit{Double 2} an\footnote{\url{http://www.doublerobotics.com/}(letzter Aufruf: 31. Dezember 2016)}. Dieses oder ähnliche Systeme werden auch als \textit{\acf{tps}} bezeichnet. Durch ein \acl{tps} entsteht aufseiten des Benutzers das Gefühl, sich in der Umgebung des \acs{tps} \textit{präsent} zu fühlen, obwohl er dies nicht direkt ist. Abhängig ist dieses Gefühl durch den Grad der Immersion\footnote{Immersion, bezeichnet das Maß, in eine virtuelle oder entfernte reale Welt einzutauchen und sich in dieser präsent zu fühlen \cite{Rossler2009}} des Telepräsenzsystems \cite{Rossler2009}. Aufbauend auf dem bislang Beschriebenen kann aus einer Kombination eines Eyetracking-Systems mit einem \acs{tps} ein potenziell hilfreiches System besonders für Personen mit Sprach- und Bewegungseinschränkungen entstehen. 

%Die Teleoperation eines mobilen Robotersystems einzig auf Augen- und Blickbewegungen basierend zu ermöglichen, stellt eine Herausforderung dar. Die vorliegende Arbeit bietet zwei mögliche Strategien \bzw Steuermethoden an, einen mobilen Roboter mithilfe eines Eyetracking-Systems zu steuern, um besonders Personen mit Sprach- und Bewegungseinschränkungen eine Erweiterung der Kommunikations- und Interaktionsfähigkeiten anzubieten, damit diese ihre Wünsche und Pläne zunehmend eigenständig umsetzen können. 
Aus dieser Motivation heraus, ergibt sich für die vorliegende Abschlussarbeit folgende Zielsetzung.

\section{Zielsetzung}
\label{section:zielsetzung}
Ziel dieser Abschlussarbeit ist es, eine Strategie für eine blick- und augenbasierte Steuerung eines mobilen Roboters mithilfe eines stationären Eyetracking-Systems in Form eines Softwareprototyps zu realisieren. Hierfür sollen zwei unterschiedliche Steuermethoden in Bezug auf die Handhabung, die Machbarkeit und die Präzision einer derartigen Mensch-Roboter-Interaktion untersucht werden. Ferner soll für beide Steuermethoden ein sofortiger Stoppmechanismus in Form eines \enquote{Panikschalters} realisiert und beurteilt werden. Damit stellt diese Arbeit einen Teilschritt hin zu einem System dar, das unter Verwendung eines mobilen \acf{tps} in Kombination mit einem Eyetracking-System in Zukunft die Kommunikations- und Interaktionsmöglichkeit von Personen mit Sprach- und Bewegungseinschränkungen erleichtern und erweitern soll. Langfristiges Ziel in weiteren Projektschritten ist es, ausgewählte Interaktionsmöglichkeiten durch eine automatische Objektklassifikation in den Videobildern des \acs{tps} umzusetzen. Bislang besteht die Kommunikation von Personen mit Sprach- und Bewegungseinschränkungen, wie oben beschrieben, weitgehend in einer Interaktion mittels statischer Inhalte.

\section{Gliederung}
\label{section:gliederung}

Nach der Einleitung im aktuellen Kapitel,- sollen im folgenden Kapitel~\enquote{Grundlagen} zunächst die anatomischen~(\ref{subsect:topgraf}) und motorischen~(\ref{subsection:okumot}) Aspekte des Auges dargestellt werden. Weiter wird auf die Erkrankungen mit Bewegungseinschränkungen bei erhaltener Augenbewegung eingegangen (\ref{subsect:erkrank}). Danach folgt eine Beschreibung des Eyetracking-Systems als technisches Hilfsmittel (\ref{section:eyetracker}). Hierbei liefert Abschnitt~(\ref{section:eyeMet}) einen Überblick über die Eyetracking-Methoden. Abschnitt~(\ref{section:vidMet}) stellt die für die Arbeit verwendeten videobasierten Eyetrackingsysteme vor. Im Abschnitt~\ref{subsection:eingabemech} wird der spezielle Nutzen von Eyetracking-Systemen als Eingabegerät zur Steuerung einer Benutzerschnittstelle erörtert. Im letzten Teil des Kapitels folgt zunächst die Unterscheidung der für diese Arbeit wichtigen Begriffe der \textit{Telepräsenz} und \textit{Teleoperation} (\ref{section:tele}). Im Anschluss (\ref{subsection:komponenten}) werden der allgemeine Aufbau von \acs{tps} und die möglichen Anwendungsgebiete dieser Systeme dargestellt. Abschließend wird auf die speziellen Anforderungen für eine Steuerung aus der Ferne eingegangen (\ref{section:steuerung}). 

Das Kapitel~\ref{chapter:fragestellung} dient der Schilderung der beiden Steuerungsmodelle~(\ref{section:modellbildung} und \ref{section:steurungsmodell}) und der relevanten Testmerkmale~(\ref{sect:testmerkmale}).

Die Beschreibung der Implementierung der relevanten Systemkomponenten folgt in Kapitel~\ref{chapter:implementierung}. Zunächst wird auf die optischen Eigenschaften des Softwareprototyps eingegangen (\ref{sect:gui}). Abschnitt~\ref{section:tpsI} und \ref{subsection:robotsteuerung} führen in die verwendete Schnittstelle des mobilen Robotersystems (Roomba 620) ein. Die Darstellung der zweiten verwendeten Komponente \et \iV der Firma \acf{smi} und die Umsetzung der Augengesten folgen in den Abschnitten~\ref{section:eyetrackingI} und \ref{section:augengestenerkennung}. Es folgen die Abschnitte zur Softwarearchitektur~(\ref{section:architektur}) und der technischen Umsetzung~(\ref{section:techkomp}).

In Kapitel \enquote{Evaluation} werden der Versuchsaufbau~(\ref{section:versuchsaufbau}) und die Versuchsdurchführung~(\ref{section:versuchsdurchführung}) beschrieben.

Alle gewonnenen Ergebnisse (\ref{section:versuchsergebnisse}) der Abschlussarbeit und deren Diskussion (\ref{section:Diskusion}) werden im Kapitel \ref{chapter:ergebnisse} dargelegt.

Zum Abschluss der vorliegenden Arbeit werden im Kapitel~\ref{chapter:zusammenfassung} die wichtigsten Ergebnisse resümiert und ein Fazit für mögliche weitere Systeme gezogen.
